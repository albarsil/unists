{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import sklearn.metrics as metrics\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import codecs\n",
    "from unidecode import unidecode\n",
    "import pickle\n",
    "import string\n",
    "import decimal\n",
    "import sys\n",
    "import pickle\n",
    "import pyodbc\n",
    "import sys\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.externals import joblib\n",
    "from pandas.io.sql import read_sql\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from nltk.stem.snowball import PortugueseStemmer\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import os.path\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import RandomOverSampler \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import cohen_kappa_score, make_scorer\n",
    "from sklearn import preprocessing\n",
    "import codecs\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import feature_selection\n",
    "\n",
    "# ML\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCombinations(params):\n",
    "    comb = [len(v) for v in params.values()]\n",
    "    s = 1\n",
    "    for x in comb:\n",
    "        s = s * x\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_dataframe(path):\n",
    "    with codecs.open(path, 'r', encoding='utf-8') as reader:\n",
    "        d = json.load(reader)\n",
    "        \n",
    "    return pd.DataFrame.from_dict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2normalize(xdf):\n",
    "    return pd.DataFrame(preprocessing.normalize(xdf, norm='l2', axis=1, copy=True, return_norm=False),\n",
    "             columns=xdf.columns, index=xdf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(gold_values, sys_values, name):\n",
    "    \"\"\"Docstring.\"\"\"\n",
    "    pearson = pearsonr(gold_values, sys_values)[0]\n",
    "    absolute_diff = gold_values - sys_values\n",
    "    mse = (absolute_diff ** 2).mean()\n",
    "\n",
    "    print()\n",
    "    print('Similarity evaluation\\t' + name)\n",
    "    print('Pearson\\t\\tMean Squared Error')\n",
    "    print('-------\\t\\t------------------')\n",
    "    print('{:7.2f}\\t\\t{:18.2f}'.format(pearson, mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureSelection(x, y):\n",
    "\n",
    "    def f_regression(X,Y):\n",
    "        return feature_selection.f_regression(X,Y,center=False) #center=True (the default) would not work (\"ValueError: center=True only allowed for dense data\") but should presumably work in general\n",
    "\n",
    "    featureSelector = feature_selection.SelectKBest(score_func=f_regression,k=4)\n",
    "    featureSelector.fit(x,y)\n",
    "    selected_index = [zero_based_index for zero_based_index in list(featureSelector.get_support(indices=True))]\n",
    "    \n",
    "    return selected_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "setP1 = json_to_dataframe('C:/Users/Asilva/Dropbox/unisinos-pipca-aleksejs-allan-sandro/Data/Processed/GloVe/setP1_processed.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "setP2 = json_to_dataframe('C:/Users/Asilva/Dropbox/unisinos-pipca-aleksejs-allan-sandro/Data/Processed/GloVe/setP2_processed.json')\n",
    "setP3 = json_to_dataframe('C:/Users/Asilva/Dropbox/unisinos-pipca-aleksejs-allan-sandro/Data/Processed/GloVe/setP3_processed.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "setP1 = pd.concat([setP1, setP2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "setP2 = setP3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "setP1 = setP1.sort_values('index', ascending=True)\n",
    "setP1.drop('index', axis=1, inplace=True)\n",
    "setP2 = setP2.sort_values('index', ascending=True)\n",
    "setP2.drop('index', axis=1, inplace=True)\n",
    "setP1['target'] = [float(x) for x in setP1['target']]\n",
    "setP2['target'] = [float(x) for x in setP2['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antonyms</th>\n",
       "      <th>embeddings_diff</th>\n",
       "      <th>embeddings_max</th>\n",
       "      <th>embeddings_pca</th>\n",
       "      <th>ngram_proportion</th>\n",
       "      <th>target</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>uncommon_proportion</th>\n",
       "      <th>word_overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>antonyms</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embeddings_diff</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.488740</td>\n",
       "      <td>0.920143</td>\n",
       "      <td>0.413633</td>\n",
       "      <td>0.405456</td>\n",
       "      <td>0.470050</td>\n",
       "      <td>-0.360695</td>\n",
       "      <td>0.520487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embeddings_max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.488740</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.359233</td>\n",
       "      <td>0.299323</td>\n",
       "      <td>0.287358</td>\n",
       "      <td>0.309807</td>\n",
       "      <td>-0.259425</td>\n",
       "      <td>0.867714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embeddings_pca</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.920143</td>\n",
       "      <td>0.359233</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.356607</td>\n",
       "      <td>0.337837</td>\n",
       "      <td>0.404733</td>\n",
       "      <td>-0.323429</td>\n",
       "      <td>0.384255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ngram_proportion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.413633</td>\n",
       "      <td>0.299323</td>\n",
       "      <td>0.356607</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.554951</td>\n",
       "      <td>0.765326</td>\n",
       "      <td>-0.215727</td>\n",
       "      <td>0.347661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.405456</td>\n",
       "      <td>0.287358</td>\n",
       "      <td>0.337837</td>\n",
       "      <td>0.554951</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.647781</td>\n",
       "      <td>-0.203088</td>\n",
       "      <td>0.355776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.470050</td>\n",
       "      <td>0.309807</td>\n",
       "      <td>0.404733</td>\n",
       "      <td>0.765326</td>\n",
       "      <td>0.647781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.235459</td>\n",
       "      <td>0.365464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uncommon_proportion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.360695</td>\n",
       "      <td>-0.259425</td>\n",
       "      <td>-0.323429</td>\n",
       "      <td>-0.215727</td>\n",
       "      <td>-0.203088</td>\n",
       "      <td>-0.235459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.239150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_overlap</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.520487</td>\n",
       "      <td>0.867714</td>\n",
       "      <td>0.384255</td>\n",
       "      <td>0.347661</td>\n",
       "      <td>0.355776</td>\n",
       "      <td>0.365464</td>\n",
       "      <td>-0.239150</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     antonyms  embeddings_diff  embeddings_max  \\\n",
       "antonyms                  NaN              NaN             NaN   \n",
       "embeddings_diff           NaN         1.000000        0.488740   \n",
       "embeddings_max            NaN         0.488740        1.000000   \n",
       "embeddings_pca            NaN         0.920143        0.359233   \n",
       "ngram_proportion          NaN         0.413633        0.299323   \n",
       "target                    NaN         0.405456        0.287358   \n",
       "tfidf                     NaN         0.470050        0.309807   \n",
       "uncommon_proportion       NaN        -0.360695       -0.259425   \n",
       "word_overlap              NaN         0.520487        0.867714   \n",
       "\n",
       "                     embeddings_pca  ngram_proportion    target     tfidf  \\\n",
       "antonyms                        NaN               NaN       NaN       NaN   \n",
       "embeddings_diff            0.920143          0.413633  0.405456  0.470050   \n",
       "embeddings_max             0.359233          0.299323  0.287358  0.309807   \n",
       "embeddings_pca             1.000000          0.356607  0.337837  0.404733   \n",
       "ngram_proportion           0.356607          1.000000  0.554951  0.765326   \n",
       "target                     0.337837          0.554951  1.000000  0.647781   \n",
       "tfidf                      0.404733          0.765326  0.647781  1.000000   \n",
       "uncommon_proportion       -0.323429         -0.215727 -0.203088 -0.235459   \n",
       "word_overlap               0.384255          0.347661  0.355776  0.365464   \n",
       "\n",
       "                     uncommon_proportion  word_overlap  \n",
       "antonyms                             NaN           NaN  \n",
       "embeddings_diff                -0.360695      0.520487  \n",
       "embeddings_max                 -0.259425      0.867714  \n",
       "embeddings_pca                 -0.323429      0.384255  \n",
       "ngram_proportion               -0.215727      0.347661  \n",
       "target                         -0.203088      0.355776  \n",
       "tfidf                          -0.235459      0.365464  \n",
       "uncommon_proportion             1.000000     -0.239150  \n",
       "word_overlap                   -0.239150      1.000000  "
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setP1.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "setP1 = setP1.drop('uncommon_proportion', 1)\n",
    "setP1 = setP1.drop('embeddings_pca', 1)\n",
    "setP1 = setP1.drop('embeddings_max', 1)\n",
    "setP1 = setP1.drop('antonyms', 1)\n",
    "\n",
    "setP2 = setP2.drop('uncommon_proportion', 1)\n",
    "setP2 = setP2.drop('embeddings_pca', 1)\n",
    "setP2 = setP2.drop('embeddings_max', 1)\n",
    "setP2 = setP2.drop('antonyms', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = setP1.drop('target', 1)\n",
    "y_train = setP1['target']\n",
    "x_test = setP2.drop('target', 1)\n",
    "y_test = setP2['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featureSelection(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = l2normalize(x_train)\n",
    "# x_test = l2normalize(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\tSVR RBF\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "   0.68\t\t              0.41\n"
     ]
    }
   ],
   "source": [
    "model_ml = SVR(kernel='poly', gamma=0.5, epsilon=0.1, C=1)\n",
    "y_predicted = model_ml.fit(x_train, y_train).predict(x_test)\n",
    "print_result(y_test, y_predicted, 'SVR RBF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\tSVR RBF\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "   0.67\t\t              0.42\n"
     ]
    }
   ],
   "source": [
    "model_ml = SVR(kernel='poly', C=1, degree=3)\n",
    "y_predicted = model_ml.fit(x_train, y_train).predict(x_test)\n",
    "print_result(y_test, y_predicted, 'SVR RBF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\tSVR RBF\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "   0.68\t\t              0.42\n"
     ]
    }
   ],
   "source": [
    "model_ml = SVR(kernel='linear', C=1)\n",
    "y_predicted = model_ml.fit(x_train, y_train).predict(x_test)\n",
    "print_result(y_test, y_predicted, 'SVR RBF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\tRandomForest\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "   0.64\t\t              0.46\n"
     ]
    }
   ],
   "source": [
    "model_ml = RandomForestRegressor(n_estimators=200,n_jobs=-1,bootstrap=True)\n",
    "y_predicted = model_ml.fit(x_train, y_train).predict(x_test)\n",
    "print_result(y_test, y_predicted, 'RandomForest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\tLinearRegression\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "   0.68\t\t              0.41\n"
     ]
    }
   ],
   "source": [
    "model_ml = linear_model.LinearRegression(n_jobs=-1)\n",
    "y_predicted = model_ml.fit(x_train, y_train).predict(x_test)\n",
    "print_result(y_test, y_predicted, 'LinearRegression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\tRidgeRegression\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "   0.67\t\t              0.42\n"
     ]
    }
   ],
   "source": [
    "model_ml = linear_model.Ridge()\n",
    "y_predicted = model_ml.fit(x_train, y_train).predict(x_test)\n",
    "print_result(y_test, y_predicted, 'RidgeRegression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\tBayesianRidgeRegression\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "   0.68\t\t              0.41\n"
     ]
    }
   ],
   "source": [
    "model_ml = linear_model.BayesianRidge(n_iter=1000,normalize=False)\n",
    "y_predicted = model_ml.fit(x_train, y_train).predict(x_test)\n",
    "print_result(y_test, y_predicted, 'BayesianRidgeRegression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1680 candidates, totalling 3360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 3360 out of 3360 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\tNeuralNetworkRegression\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "   0.67\t\t              0.42\n"
     ]
    }
   ],
   "source": [
    "mlp_param_grid = dict(\n",
    "    max_iter=[1000],\n",
    "    momentum=[0,0.1,0.3,0.5,0.7],\n",
    "    learning_rate_init=[0.012,0.013,0.015,0.017,0.11,0.13,0.21],\n",
    "    hidden_layer_sizes=[(15,),(25,),(35,),(45,),(55,),(60,)],\n",
    "    solver=['adam'],\n",
    "    learning_rate=['invscaling','adaptive'],\n",
    "    activation=['tanh', 'relu'],\n",
    "    early_stopping=[True, False],\n",
    "    shuffle=[True],\n",
    "    batch_size=[500]\n",
    ")\n",
    "model_ml = MLPRegressor()\n",
    "param_search = GridSearchCV(\n",
    "            estimator=model_ml, \n",
    "            param_grid=mlp_param_grid,\n",
    "            n_jobs=1,\n",
    "            scoring='neg_mean_squared_error',\n",
    "            cv = 2,\n",
    "            refit=True,\n",
    "            verbose=1\n",
    "        )\n",
    "model_ml = param_search\n",
    "y_predicted = model_ml.fit(x_train, y_train).predict(x_test)\n",
    "print_result(y_test, y_predicted, 'NeuralNetworkRegression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSQ (cross_validation): -0.42 (+/- 0.08)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(\n",
    "    model_ml,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    cv=10,\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "print(\"MSQ (cross_validation): %0.2f (+/- %0.2f)\"\n",
    "      % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
